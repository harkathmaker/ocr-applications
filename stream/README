*****************************
** Current Status of Files **
*****************************
generate_results.py:
	-- Not implemented

options.h:
	-- Support for parallel_stream.c and serial_stream.c

parallel_db_edt_breakdown_stream.c:
	-- getopt is not supported

parallel_edt_breakdown_stream.c:
	-- getopt is not supported

parallel_db_breakdown_stream.c:
	-- getopt is not supported

parallel_stream.c:
	-- Full getopt is supported

serial_stream.c
	-- Full getopt is supported

************************
** Build Instructions **
************************

To build all files:
	make all 

To build specific file: 
	make <file_name>.o
	ex: make serial_stream.o

***********************
** Overview of Files **
***********************
generate_results.py:
	-- Generates results and graphs for serial and parallel stream versions

options.h:
	-- Contains getopt parsing for *_stream.c files

parallel_db_edt_breakdown_stream.c:

parallel_db_breakdown_stream.c:
	-- Represents a datablock of size "db_size" by "split" number of "chunk"s
	   where chunk = db_size / split
	-- "db_size" and "split" should be set up such that db_size % split = 0
	-- partial a, b, and c "arrays" each of size "chunk" and timings of size iterations are stored in EACH datablock 
	   ex: db_size = 10, split = 2, chunk = 10 / 2 = 5
	       So, 2 datablocks with each a, b, c array having size 5 will be created
		   instead of 1 datablock of size 10 for each a, b, c, array
		                   a                      b                          c                               timings
		datablock0 = [0 to (chunk - 1)] [chunk to (2 * chunk - 1)] [2 * chunk to (3 * chunk - 1)] [3 * chunk to (3 * chunk + iterations)]
		datablock1 = [0 to (chunk - 1)] [chunk to (2 * chunk - 1)] [2 * chunk to (3 * chunk - 1)] [3 * chunk to (3 * chunk + iterations)]


parallel_stream.c:
	-- Simple parallel implementation of stream in OCR.
	-- Datablock are divided implicitly via indexing set by "split"
	-- Each instance of pipelineEDT operates on db_size / split number of elements
	-- All vector operations are run in a single edt (pipelineEDT) similar to serial_stream.c
	   with the difference being that there will be "split" instances of pipelineEDT each
	   operating on db_size / split.

serial_edt_breakdown_stream.c:
	-- Breaks apart vector operations (COPY, SCALE, ADD, TRIAD) into 
	   separate EDTs

serial_stream.c:
	-- Serial implementation of stream in OCR.
	-- Vector operations are run in a single EDT (iterEdt) in the following order: 
	   COPY --> SCALE --> ADD --> TRIAD

- e | --export CSV files:
	Timing data is reported in the following format:
	Tria1 1, Trial 2, Trial 3, ... , Trial N, Average of N Trials

***********
** Notes **
***********